{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbxI5snY9CQvUx4x+h0LgW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ulrikSebastienR/2021-Coding-Basic/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJoIGL4vmoKZ"
      },
      "source": [
        "#https://www.kdnuggets.com/2020/07/easy-guide-data-preprocessing-python.html\n",
        "#https://machinelearningmastery.com/data-preparation-for-machine-learning-7-day-mini-course/\n",
        "# For simple imputer we first need to convert DF to array and then array to DF as fit and fit_transform methods only apply on arrays.\n",
        "# How to simple impute without converting to and from array with df[iloc]\n",
        "# KNN imputer\n",
        "# RFE or recursive feature elimination\n",
        "# Label Encoder\n",
        "# One Hot Encoder\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv'\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0MJXfw5nZj4",
        "outputId": "70813266-03d1-4406-d256-7c7ea879d2a7"
      },
      "source": [
        "df = pd.read_csv(url) # without passing header and na_values = 'indicator of na values', we might not get the proper missing values by df.isna()\n",
        "print(df)\n",
        "print(df.describe())\n",
        "df.isna().sum() "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     2  1   530101  38.50   66  28  ... 2.2 2.3 11300 00000 00000.1 2.4\n",
            "0    1  1   534817   39.2   88  20  ...   3   2  2208     0       0   2\n",
            "1    2  1   530334  38.30   40  24  ...   1   2     0     0       0   1\n",
            "2    1  9  5290409  39.10  164  84  ...   2   1  2208     0       0   1\n",
            "3    2  1   530255  37.30  104  35  ...   2   2  4300     0       0   2\n",
            "4    2  1   528355      ?    ?   ?  ...   1   2     0     0       0   2\n",
            "..  .. ..      ...    ...  ...  ..  ...  ..  ..   ...   ...     ...  ..\n",
            "294  1  1   533886      ?  120  70  ...   3   2  3205     0       0   2\n",
            "295  2  1   527702  37.20   72  24  ...   3   1  2208     0       0   1\n",
            "296  1  1   529386  37.50   72  30  ...   2   1  3205     0       0   2\n",
            "297  1  1   530612  36.50  100  24  ...   1   1  2208     0       0   1\n",
            "298  1  1   534618   37.2   40  20  ...   3   2  6112     0       0   2\n",
            "\n",
            "[299 rows x 28 columns]\n",
            "               1        530101  ...      00000.1         2.4\n",
            "count  299.00000  2.990000e+02  ...   299.000000  299.000000\n",
            "mean     1.64214  1.087748e+06  ...     7.387960    1.668896\n",
            "std      2.17730  1.532026e+06  ...   127.749768    0.471399\n",
            "min      1.00000  5.184760e+05  ...     0.000000    1.000000\n",
            "25%      1.00000  5.289040e+05  ...     0.000000    1.000000\n",
            "50%      1.00000  5.303100e+05  ...     0.000000    2.000000\n",
            "75%      1.00000  5.347360e+05  ...     0.000000    2.000000\n",
            "max      9.00000  5.305629e+06  ...  2209.000000    2.000000\n",
            "\n",
            "[8 rows x 7 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2          0\n",
              "1          0\n",
              "530101     0\n",
              "38.50      0\n",
              "66         0\n",
              "28         0\n",
              "3          0\n",
              "3.1        0\n",
              "?          0\n",
              "2.1        0\n",
              "5          0\n",
              "4          0\n",
              "4.1        0\n",
              "?.1        0\n",
              "?.2        0\n",
              "?.3        0\n",
              "3.2        0\n",
              "5.1        0\n",
              "45.00      0\n",
              "8.40       0\n",
              "?.4        0\n",
              "?.5        0\n",
              "2.2        0\n",
              "2.3        0\n",
              "11300      0\n",
              "00000      0\n",
              "00000.1    0\n",
              "2.4        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqH6j8spvK6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e76596c-bd1b-4c99-b2a1-9a5c84712f35"
      },
      "source": [
        "df = pd.read_csv(url,header=None, na_values='?') #Using na_values = '?' automatically fills the na_values with NaN and header = None stops header to be computed from data columns.\n",
        "print(df)\n",
        "print(df.describe()) # In df.describe if the row 'min' has values 0 that means there might be missing values.\n",
        "print(df.isna().sum())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      0   1        2     3      4     5    6   ...   21   22  23     24  25  26  27\n",
            "0    2.0   1   530101  38.5   66.0  28.0  3.0  ...  NaN  2.0   2  11300   0   0   2\n",
            "1    1.0   1   534817  39.2   88.0  20.0  NaN  ...  2.0  3.0   2   2208   0   0   2\n",
            "2    2.0   1   530334  38.3   40.0  24.0  1.0  ...  NaN  1.0   2      0   0   0   1\n",
            "3    1.0   9  5290409  39.1  164.0  84.0  4.0  ...  5.3  2.0   1   2208   0   0   1\n",
            "4    2.0   1   530255  37.3  104.0  35.0  NaN  ...  NaN  2.0   2   4300   0   0   2\n",
            "..   ...  ..      ...   ...    ...   ...  ...  ...  ...  ...  ..    ...  ..  ..  ..\n",
            "295  1.0   1   533886   NaN  120.0  70.0  4.0  ...  NaN  3.0   2   3205   0   0   2\n",
            "296  2.0   1   527702  37.2   72.0  24.0  3.0  ...  3.3  3.0   1   2208   0   0   1\n",
            "297  1.0   1   529386  37.5   72.0  30.0  4.0  ...  NaN  2.0   1   3205   0   0   2\n",
            "298  1.0   1   530612  36.5  100.0  24.0  3.0  ...  3.4  1.0   1   2208   0   0   1\n",
            "299  1.0   1   534618  37.2   40.0  20.0  NaN  ...  1.0  3.0   2   6112   0   0   2\n",
            "\n",
            "[300 rows x 28 columns]\n",
            "               0           1   ...           26          27\n",
            "count  299.000000  300.000000  ...   300.000000  300.000000\n",
            "mean     1.397993    1.640000  ...     7.363333    1.670000\n",
            "std      0.490305    2.173972  ...   127.536674    0.470998\n",
            "min      1.000000    1.000000  ...     0.000000    1.000000\n",
            "25%      1.000000    1.000000  ...     0.000000    1.000000\n",
            "50%      1.000000    1.000000  ...     0.000000    2.000000\n",
            "75%      2.000000    1.000000  ...     0.000000    2.000000\n",
            "max      2.000000    9.000000  ...  2209.000000    2.000000\n",
            "\n",
            "[8 rows x 28 columns]\n",
            "0       1\n",
            "1       0\n",
            "2       0\n",
            "3      60\n",
            "4      24\n",
            "5      58\n",
            "6      56\n",
            "7      69\n",
            "8      47\n",
            "9      32\n",
            "10     55\n",
            "11     44\n",
            "12     56\n",
            "13    104\n",
            "14    106\n",
            "15    247\n",
            "16    102\n",
            "17    118\n",
            "18     29\n",
            "19     33\n",
            "20    165\n",
            "21    198\n",
            "22      1\n",
            "23      0\n",
            "24      0\n",
            "25      0\n",
            "26      0\n",
            "27      0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_SMKfSQbgkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5062bdf-ca05-4810-a105-0d7e67993104"
      },
      "source": [
        "import numpy as np\n",
        "df_array = df.to_numpy() # To Convert to array\n",
        "print(df_array, df_array.shape)\n",
        "# For simple imputer we first need to convert DF to array and then array to DF as fit and fit_transform methods only apply on arrays."
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.00000e+00 1.00000e+00 5.30101e+05 ... 0.00000e+00 0.00000e+00\n",
            "  2.00000e+00]\n",
            " [1.00000e+00 1.00000e+00 5.34817e+05 ... 0.00000e+00 0.00000e+00\n",
            "  2.00000e+00]\n",
            " [2.00000e+00 1.00000e+00 5.30334e+05 ... 0.00000e+00 0.00000e+00\n",
            "  1.00000e+00]\n",
            " ...\n",
            " [1.00000e+00 1.00000e+00 5.29386e+05 ... 0.00000e+00 0.00000e+00\n",
            "  2.00000e+00]\n",
            " [1.00000e+00 1.00000e+00 5.30612e+05 ... 0.00000e+00 0.00000e+00\n",
            "  1.00000e+00]\n",
            " [1.00000e+00 1.00000e+00 5.34618e+05 ... 0.00000e+00 0.00000e+00\n",
            "  2.00000e+00]] (300, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn4CZIHHl23i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db1fcec-2507-4f70-dd21-a5a3791e33fe"
      },
      "source": [
        "impute = SimpleImputer()\n",
        "X = impute.fit_transform(df_array)\n",
        "print(X)\n",
        "df = pd.DataFrame(X) # A DataFrame can directly be constructed from an array.\n",
        "print(df)\n",
        "print(df.describe())\n",
        "print(df.isna().sum())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.00000e+00 1.00000e+00 5.30101e+05 ... 0.00000e+00 0.00000e+00\n",
            "  2.00000e+00]\n",
            " [1.00000e+00 1.00000e+00 5.34817e+05 ... 0.00000e+00 0.00000e+00\n",
            "  2.00000e+00]\n",
            " [2.00000e+00 1.00000e+00 5.30334e+05 ... 0.00000e+00 0.00000e+00\n",
            "  1.00000e+00]\n",
            " ...\n",
            " [1.00000e+00 1.00000e+00 5.29386e+05 ... 0.00000e+00 0.00000e+00\n",
            "  2.00000e+00]\n",
            " [1.00000e+00 1.00000e+00 5.30612e+05 ... 0.00000e+00 0.00000e+00\n",
            "  1.00000e+00]\n",
            " [1.00000e+00 1.00000e+00 5.34618e+05 ... 0.00000e+00 0.00000e+00\n",
            "  2.00000e+00]]\n",
            "      0    1          2          3      4   ...   23       24   25   26   27\n",
            "0    2.0  1.0   530101.0  38.500000   66.0  ...  2.0  11300.0  0.0  0.0  2.0\n",
            "1    1.0  1.0   534817.0  39.200000   88.0  ...  2.0   2208.0  0.0  0.0  2.0\n",
            "2    2.0  1.0   530334.0  38.300000   40.0  ...  2.0      0.0  0.0  0.0  1.0\n",
            "3    1.0  9.0  5290409.0  39.100000  164.0  ...  1.0   2208.0  0.0  0.0  1.0\n",
            "4    2.0  1.0   530255.0  37.300000  104.0  ...  2.0   4300.0  0.0  0.0  2.0\n",
            "..   ...  ...        ...        ...    ...  ...  ...      ...  ...  ...  ...\n",
            "295  1.0  1.0   533886.0  38.167917  120.0  ...  2.0   3205.0  0.0  0.0  2.0\n",
            "296  2.0  1.0   527702.0  37.200000   72.0  ...  1.0   2208.0  0.0  0.0  1.0\n",
            "297  1.0  1.0   529386.0  37.500000   72.0  ...  1.0   3205.0  0.0  0.0  2.0\n",
            "298  1.0  1.0   530612.0  36.500000  100.0  ...  1.0   2208.0  0.0  0.0  1.0\n",
            "299  1.0  1.0   534618.0  37.200000   40.0  ...  2.0   6112.0  0.0  0.0  2.0\n",
            "\n",
            "[300 rows x 28 columns]\n",
            "               0           1   ...           26          27\n",
            "count  300.000000  300.000000  ...   300.000000  300.000000\n",
            "mean     1.397993    1.640000  ...     7.363333    1.670000\n",
            "std      0.489484    2.173972  ...   127.536674    0.470998\n",
            "min      1.000000    1.000000  ...     0.000000    1.000000\n",
            "25%      1.000000    1.000000  ...     0.000000    1.000000\n",
            "50%      1.000000    1.000000  ...     0.000000    2.000000\n",
            "75%      2.000000    1.000000  ...     0.000000    2.000000\n",
            "max      2.000000    9.000000  ...  2209.000000    2.000000\n",
            "\n",
            "[8 rows x 28 columns]\n",
            "0     0\n",
            "1     0\n",
            "2     0\n",
            "3     0\n",
            "4     0\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    0\n",
            "11    0\n",
            "12    0\n",
            "13    0\n",
            "14    0\n",
            "15    0\n",
            "16    0\n",
            "17    0\n",
            "18    0\n",
            "19    0\n",
            "20    0\n",
            "21    0\n",
            "22    0\n",
            "23    0\n",
            "24    0\n",
            "25    0\n",
            "26    0\n",
            "27    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vchxds815vDJ"
      },
      "source": [
        "# Alternative method https://datascience.stackexchange.com/questions/51890/how-to-use-simpleimputer-class-to-replace-missing-values-with-mean-values-using"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cZ6ciCwL3fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e35be8-5626-4aaf-95df-cf95daf36807"
      },
      "source": [
        "df1 = pd.read_csv(url,header=None, na_values='?')\n",
        "print(df1)\n",
        "print(df1.describe()) # In df.describe if the row 'min' has values 0 that means there might be missing values.\n",
        "print(df1.isna().sum())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      0   1        2     3      4     5    6   ...   21   22  23     24  25  26  27\n",
            "0    2.0   1   530101  38.5   66.0  28.0  3.0  ...  NaN  2.0   2  11300   0   0   2\n",
            "1    1.0   1   534817  39.2   88.0  20.0  NaN  ...  2.0  3.0   2   2208   0   0   2\n",
            "2    2.0   1   530334  38.3   40.0  24.0  1.0  ...  NaN  1.0   2      0   0   0   1\n",
            "3    1.0   9  5290409  39.1  164.0  84.0  4.0  ...  5.3  2.0   1   2208   0   0   1\n",
            "4    2.0   1   530255  37.3  104.0  35.0  NaN  ...  NaN  2.0   2   4300   0   0   2\n",
            "..   ...  ..      ...   ...    ...   ...  ...  ...  ...  ...  ..    ...  ..  ..  ..\n",
            "295  1.0   1   533886   NaN  120.0  70.0  4.0  ...  NaN  3.0   2   3205   0   0   2\n",
            "296  2.0   1   527702  37.2   72.0  24.0  3.0  ...  3.3  3.0   1   2208   0   0   1\n",
            "297  1.0   1   529386  37.5   72.0  30.0  4.0  ...  NaN  2.0   1   3205   0   0   2\n",
            "298  1.0   1   530612  36.5  100.0  24.0  3.0  ...  3.4  1.0   1   2208   0   0   1\n",
            "299  1.0   1   534618  37.2   40.0  20.0  NaN  ...  1.0  3.0   2   6112   0   0   2\n",
            "\n",
            "[300 rows x 28 columns]\n",
            "               0           1   ...           26          27\n",
            "count  299.000000  300.000000  ...   300.000000  300.000000\n",
            "mean     1.397993    1.640000  ...     7.363333    1.670000\n",
            "std      0.490305    2.173972  ...   127.536674    0.470998\n",
            "min      1.000000    1.000000  ...     0.000000    1.000000\n",
            "25%      1.000000    1.000000  ...     0.000000    1.000000\n",
            "50%      1.000000    1.000000  ...     0.000000    2.000000\n",
            "75%      2.000000    1.000000  ...     0.000000    2.000000\n",
            "max      2.000000    9.000000  ...  2209.000000    2.000000\n",
            "\n",
            "[8 rows x 28 columns]\n",
            "0       1\n",
            "1       0\n",
            "2       0\n",
            "3      60\n",
            "4      24\n",
            "5      58\n",
            "6      56\n",
            "7      69\n",
            "8      47\n",
            "9      32\n",
            "10     55\n",
            "11     44\n",
            "12     56\n",
            "13    104\n",
            "14    106\n",
            "15    247\n",
            "16    102\n",
            "17    118\n",
            "18     29\n",
            "19     33\n",
            "20    165\n",
            "21    198\n",
            "22      1\n",
            "23      0\n",
            "24      0\n",
            "25      0\n",
            "26      0\n",
            "27      0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbFMNHnY6msV"
      },
      "source": [
        "#df1 = impute.fit_transform(df1[:,3:21]) # slice isn't working TypeError: '(slice(None, None, None), slice(3, 21, None))' is an invalid key"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eVA294J7Vk3"
      },
      "source": [
        "#df1[:,0:21] TypeError: '(slice(None, None, None), slice(0, 21, None))' is an invalid key "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXHRfcSAOV6N",
        "outputId": "f1fd0013-915b-4ecd-ba03-f034f1a34288"
      },
      "source": [
        "#after using iloc/loc \n",
        "print(df1.iloc[:,:22]) # Using index till 22 as the last index is left out so if we use use index till 21, column 21 will be left out.\n",
        "print(df1.iloc[:,:22])\n",
        "df1.iloc[:,:22] = impute.fit_transform(df1.iloc[:,:22])\n",
        "print(df1.iloc[:,:22]) #Note no need of conversion df to and from array.\n",
        "print(df1.isna().sum(), df1)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      0   1        2     3      4     5   ...   16   17    18    19   20   21\n",
            "0    2.0   1   530101  38.5   66.0  28.0  ...  3.0  5.0  45.0   8.4  NaN  NaN\n",
            "1    1.0   1   534817  39.2   88.0  20.0  ...  4.0  2.0  50.0  85.0  2.0  2.0\n",
            "2    2.0   1   530334  38.3   40.0  24.0  ...  1.0  1.0  33.0   6.7  NaN  NaN\n",
            "3    1.0   9  5290409  39.1  164.0  84.0  ...  3.0  NaN  48.0   7.2  3.0  5.3\n",
            "4    2.0   1   530255  37.3  104.0  35.0  ...  NaN  NaN  74.0   7.4  NaN  NaN\n",
            "..   ...  ..      ...   ...    ...   ...  ...  ...  ...   ...   ...  ...  ...\n",
            "295  1.0   1   533886   NaN  120.0  70.0  ...  NaN  5.0  55.0  65.0  NaN  NaN\n",
            "296  2.0   1   527702  37.2   72.0  24.0  ...  4.0  4.0  44.0   NaN  3.0  3.3\n",
            "297  1.0   1   529386  37.5   72.0  30.0  ...  3.0  5.0  60.0   6.8  NaN  NaN\n",
            "298  1.0   1   530612  36.5  100.0  24.0  ...  4.0  4.0  50.0   6.0  3.0  3.4\n",
            "299  1.0   1   534618  37.2   40.0  20.0  ...  4.0  1.0  36.0  62.0  1.0  1.0\n",
            "\n",
            "[300 rows x 22 columns]\n",
            "      0   1        2     3      4     5   ...   16   17    18    19   20   21\n",
            "0    2.0   1   530101  38.5   66.0  28.0  ...  3.0  5.0  45.0   8.4  NaN  NaN\n",
            "1    1.0   1   534817  39.2   88.0  20.0  ...  4.0  2.0  50.0  85.0  2.0  2.0\n",
            "2    2.0   1   530334  38.3   40.0  24.0  ...  1.0  1.0  33.0   6.7  NaN  NaN\n",
            "3    1.0   9  5290409  39.1  164.0  84.0  ...  3.0  NaN  48.0   7.2  3.0  5.3\n",
            "4    2.0   1   530255  37.3  104.0  35.0  ...  NaN  NaN  74.0   7.4  NaN  NaN\n",
            "..   ...  ..      ...   ...    ...   ...  ...  ...  ...   ...   ...  ...  ...\n",
            "295  1.0   1   533886   NaN  120.0  70.0  ...  NaN  5.0  55.0  65.0  NaN  NaN\n",
            "296  2.0   1   527702  37.2   72.0  24.0  ...  4.0  4.0  44.0   NaN  3.0  3.3\n",
            "297  1.0   1   529386  37.5   72.0  30.0  ...  3.0  5.0  60.0   6.8  NaN  NaN\n",
            "298  1.0   1   530612  36.5  100.0  24.0  ...  4.0  4.0  50.0   6.0  3.0  3.4\n",
            "299  1.0   1   534618  37.2   40.0  20.0  ...  4.0  1.0  36.0  62.0  1.0  1.0\n",
            "\n",
            "[300 rows x 22 columns]\n",
            "      0    1          2          3   ...    18         19        20        21\n",
            "0    2.0  1.0   530101.0  38.500000  ...  45.0   8.400000  2.037037  3.019608\n",
            "1    1.0  1.0   534817.0  39.200000  ...  50.0  85.000000  2.000000  2.000000\n",
            "2    2.0  1.0   530334.0  38.300000  ...  33.0   6.700000  2.037037  3.019608\n",
            "3    1.0  9.0  5290409.0  39.100000  ...  48.0   7.200000  3.000000  5.300000\n",
            "4    2.0  1.0   530255.0  37.300000  ...  74.0   7.400000  2.037037  3.019608\n",
            "..   ...  ...        ...        ...  ...   ...        ...       ...       ...\n",
            "295  1.0  1.0   533886.0  38.167917  ...  55.0  65.000000  2.037037  3.019608\n",
            "296  2.0  1.0   527702.0  37.200000  ...  44.0  24.456929  3.000000  3.300000\n",
            "297  1.0  1.0   529386.0  37.500000  ...  60.0   6.800000  2.037037  3.019608\n",
            "298  1.0  1.0   530612.0  36.500000  ...  50.0   6.000000  3.000000  3.400000\n",
            "299  1.0  1.0   534618.0  37.200000  ...  36.0  62.000000  1.000000  1.000000\n",
            "\n",
            "[300 rows x 22 columns]\n",
            "0     0\n",
            "1     0\n",
            "2     0\n",
            "3     0\n",
            "4     0\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    0\n",
            "11    0\n",
            "12    0\n",
            "13    0\n",
            "14    0\n",
            "15    0\n",
            "16    0\n",
            "17    0\n",
            "18    0\n",
            "19    0\n",
            "20    0\n",
            "21    0\n",
            "22    1\n",
            "23    0\n",
            "24    0\n",
            "25    0\n",
            "26    0\n",
            "27    0\n",
            "dtype: int64       0    1          2          3      4     5   ...   22  23     24  25  26  27\n",
            "0    2.0  1.0   530101.0  38.500000   66.0  28.0  ...  2.0   2  11300   0   0   2\n",
            "1    1.0  1.0   534817.0  39.200000   88.0  20.0  ...  3.0   2   2208   0   0   2\n",
            "2    2.0  1.0   530334.0  38.300000   40.0  24.0  ...  1.0   2      0   0   0   1\n",
            "3    1.0  9.0  5290409.0  39.100000  164.0  84.0  ...  2.0   1   2208   0   0   1\n",
            "4    2.0  1.0   530255.0  37.300000  104.0  35.0  ...  2.0   2   4300   0   0   2\n",
            "..   ...  ...        ...        ...    ...   ...  ...  ...  ..    ...  ..  ..  ..\n",
            "295  1.0  1.0   533886.0  38.167917  120.0  70.0  ...  3.0   2   3205   0   0   2\n",
            "296  2.0  1.0   527702.0  37.200000   72.0  24.0  ...  3.0   1   2208   0   0   1\n",
            "297  1.0  1.0   529386.0  37.500000   72.0  30.0  ...  2.0   1   3205   0   0   2\n",
            "298  1.0  1.0   530612.0  36.500000  100.0  24.0  ...  1.0   1   2208   0   0   1\n",
            "299  1.0  1.0   534618.0  37.200000   40.0  20.0  ...  3.0   2   6112   0   0   2\n",
            "\n",
            "[300 rows x 28 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WqJHbtoOhdY"
      },
      "source": [
        "#KNN Imputer \n",
        "from sklearn.impute import KNNImputer\n",
        "df = pd.read_csv(url, na_values='?', header= None)\n",
        "knnimputer = KNNImputer()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCi5A2WejDSX",
        "outputId": "e9ffb01e-ab6c-4559-a90c-fe65672929e2"
      },
      "source": [
        "df = knnimputer.fit_transform(df)\n",
        "print(type(df), df, df.shape)\n",
        "df = pd.DataFrame(df)\n",
        "print(type(df),df, df.isna().sum())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [[2.00000e+00 1.00000e+00 5.30101e+05 ... 0.00000e+00 0.00000e+00\n",
            "  2.00000e+00]\n",
            " [1.00000e+00 1.00000e+00 5.34817e+05 ... 0.00000e+00 0.00000e+00\n",
            "  2.00000e+00]\n",
            " [2.00000e+00 1.00000e+00 5.30334e+05 ... 0.00000e+00 0.00000e+00\n",
            "  1.00000e+00]\n",
            " ...\n",
            " [1.00000e+00 1.00000e+00 5.29386e+05 ... 0.00000e+00 0.00000e+00\n",
            "  2.00000e+00]\n",
            " [1.00000e+00 1.00000e+00 5.30612e+05 ... 0.00000e+00 0.00000e+00\n",
            "  1.00000e+00]\n",
            " [1.00000e+00 1.00000e+00 5.34618e+05 ... 0.00000e+00 0.00000e+00\n",
            "  2.00000e+00]] (300, 28)\n",
            "<class 'pandas.core.frame.DataFrame'>       0    1          2      3      4     5   ...   22   23       24   25   26   27\n",
            "0    2.0  1.0   530101.0  38.50   66.0  28.0  ...  2.0  2.0  11300.0  0.0  0.0  2.0\n",
            "1    1.0  1.0   534817.0  39.20   88.0  20.0  ...  3.0  2.0   2208.0  0.0  0.0  2.0\n",
            "2    2.0  1.0   530334.0  38.30   40.0  24.0  ...  1.0  2.0      0.0  0.0  0.0  1.0\n",
            "3    1.0  9.0  5290409.0  39.10  164.0  84.0  ...  2.0  1.0   2208.0  0.0  0.0  1.0\n",
            "4    2.0  1.0   530255.0  37.30  104.0  35.0  ...  2.0  2.0   4300.0  0.0  0.0  2.0\n",
            "..   ...  ...        ...    ...    ...   ...  ...  ...  ...      ...  ...  ...  ...\n",
            "295  1.0  1.0   533886.0  38.18  120.0  70.0  ...  3.0  2.0   3205.0  0.0  0.0  2.0\n",
            "296  2.0  1.0   527702.0  37.20   72.0  24.0  ...  3.0  1.0   2208.0  0.0  0.0  1.0\n",
            "297  1.0  1.0   529386.0  37.50   72.0  30.0  ...  2.0  1.0   3205.0  0.0  0.0  2.0\n",
            "298  1.0  1.0   530612.0  36.50  100.0  24.0  ...  1.0  1.0   2208.0  0.0  0.0  1.0\n",
            "299  1.0  1.0   534618.0  37.20   40.0  20.0  ...  3.0  2.0   6112.0  0.0  0.0  2.0\n",
            "\n",
            "[300 rows x 28 columns] 0     0\n",
            "1     0\n",
            "2     0\n",
            "3     0\n",
            "4     0\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    0\n",
            "11    0\n",
            "12    0\n",
            "13    0\n",
            "14    0\n",
            "15    0\n",
            "16    0\n",
            "17    0\n",
            "18    0\n",
            "19    0\n",
            "20    0\n",
            "21    0\n",
            "22    0\n",
            "23    0\n",
            "24    0\n",
            "25    0\n",
            "26    0\n",
            "27    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6GilyfnkTmu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c73609d-ef00-4063-b31b-e34b79ef011a"
      },
      "source": [
        "# RFE or recursive feature elimination\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "X, y = load_boston(return_X_y=True)\n",
        "print(X, type(X), X.shape, '\\n', y, type(y), y.shape)\n",
        "rfe = RFE(DecisionTreeRegressor(),5,step=1)\n",
        "print(rfe)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
            " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
            " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
            " ...\n",
            " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
            " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
            " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]] <class 'numpy.ndarray'> (506, 13) \n",
            " [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
            " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
            " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
            " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
            " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
            " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
            " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
            " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
            " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
            " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
            " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
            " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
            " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
            " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
            " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
            " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
            " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
            " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
            " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
            " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
            " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
            " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
            " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
            " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
            " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
            " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
            " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
            " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
            "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
            " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
            " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
            " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
            " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
            " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
            " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
            "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
            " 22.  11.9] <class 'numpy.ndarray'> (506,)\n",
            "RFE(estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
            "                                    max_depth=None, max_features=None,\n",
            "                                    max_leaf_nodes=None,\n",
            "                                    min_impurity_decrease=0.0,\n",
            "                                    min_impurity_split=None, min_samples_leaf=1,\n",
            "                                    min_samples_split=2,\n",
            "                                    min_weight_fraction_leaf=0.0,\n",
            "                                    presort='deprecated', random_state=None,\n",
            "                                    splitter='best'),\n",
            "    n_features_to_select=5, step=1, verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OimsOrT-VHN",
        "outputId": "a35708b9-2ab0-4ea7-c5a1-dca27eb8e572"
      },
      "source": [
        "selected_by_rfe = rfe.fit_transform(X,y)\n",
        "print(selected_by_rfe, type(selected_by_rfe), selected_by_rfe.shape)\n",
        "print(rfe.support_)\n",
        "print(rfe.ranking_)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6.3200e-03 5.3800e-01 6.5750e+00 4.0900e+00 4.9800e+00]\n",
            " [2.7310e-02 4.6900e-01 6.4210e+00 4.9671e+00 9.1400e+00]\n",
            " [2.7290e-02 4.6900e-01 7.1850e+00 4.9671e+00 4.0300e+00]\n",
            " ...\n",
            " [6.0760e-02 5.7300e-01 6.9760e+00 2.1675e+00 5.6400e+00]\n",
            " [1.0959e-01 5.7300e-01 6.7940e+00 2.3889e+00 6.4800e+00]\n",
            " [4.7410e-02 5.7300e-01 6.0300e+00 2.5050e+00 7.8800e+00]] <class 'numpy.ndarray'> (506, 5)\n",
            "[ True False False False  True  True False  True False False False False\n",
            "  True]\n",
            "[1 8 6 7 1 1 3 1 9 2 4 5 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzw2uyksERyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a9848eb-b9ac-461b-ffb5-fb72609a78a4"
      },
      "source": [
        "print('Prediction by RFE', rfe.predict(X), rfe.predict(X).shape, type(rfe.predict(X)))\n",
        "print('y', y, y.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction by RFE [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
            " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
            " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
            " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
            " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
            " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
            " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
            " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
            " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
            " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
            " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
            " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
            " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
            " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
            " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
            " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
            " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
            " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
            " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
            " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
            " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
            " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
            " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
            " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
            " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
            " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
            " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
            " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
            "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
            " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
            " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
            " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
            " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
            " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
            " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
            "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
            " 22.  11.9] (506,) <class 'numpy.ndarray'>\n",
            "y [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
            " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
            " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
            " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
            " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
            " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
            " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
            " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
            " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
            " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
            " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
            " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
            " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
            " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
            " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
            " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
            " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
            " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
            " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
            " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
            " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
            " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
            " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
            " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
            " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
            " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
            " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
            " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
            "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
            " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
            " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
            " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
            " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
            " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
            " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
            "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
            " 22.  11.9] (506,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKdR8obSk5lh",
        "outputId": "2652441f-7e22-4e16-9000-625af35020ed"
      },
      "source": [
        "import pandas as pd\n",
        "boston  = pd.DataFrame(load_boston()['data'], columns=list(load_boston()['feature_names']))\n",
        "boston['target'] = load_boston()['target']\n",
        "print(boston)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  target\n",
            "0    0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98    24.0\n",
            "1    0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14    21.6\n",
            "2    0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03    34.7\n",
            "3    0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94    33.4\n",
            "4    0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33    36.2\n",
            "..       ...   ...    ...   ...    ...  ...    ...      ...     ...    ...     ...\n",
            "501  0.06263   0.0  11.93   0.0  0.573  ...  273.0     21.0  391.99   9.67    22.4\n",
            "502  0.04527   0.0  11.93   0.0  0.573  ...  273.0     21.0  396.90   9.08    20.6\n",
            "503  0.06076   0.0  11.93   0.0  0.573  ...  273.0     21.0  396.90   5.64    23.9\n",
            "504  0.10959   0.0  11.93   0.0  0.573  ...  273.0     21.0  393.45   6.48    22.0\n",
            "505  0.04741   0.0  11.93   0.0  0.573  ...  273.0     21.0  396.90   7.88    11.9\n",
            "\n",
            "[506 rows x 14 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rlRTjD0ul00U",
        "outputId": "eaab0cf8-4bff-4a8d-fbee-c13579d512df"
      },
      "source": [
        "boston_rfe = pd.DataFrame(selected_by_rfe)\n",
        "boston_rfe['old y/target'] = boston['target']\n",
        "boston_rfe['y predicted by rfe'] = rfe.predict(X)\n",
        "boston_rfe"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>old y/target</th>\n",
              "      <th>y predicted by rfe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0.06263</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.593</td>\n",
              "      <td>2.4786</td>\n",
              "      <td>9.67</td>\n",
              "      <td>22.4</td>\n",
              "      <td>22.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0.04527</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.120</td>\n",
              "      <td>2.2875</td>\n",
              "      <td>9.08</td>\n",
              "      <td>20.6</td>\n",
              "      <td>20.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0.06076</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.976</td>\n",
              "      <td>2.1675</td>\n",
              "      <td>5.64</td>\n",
              "      <td>23.9</td>\n",
              "      <td>23.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>0.10959</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.794</td>\n",
              "      <td>2.3889</td>\n",
              "      <td>6.48</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.030</td>\n",
              "      <td>2.5050</td>\n",
              "      <td>7.88</td>\n",
              "      <td>11.9</td>\n",
              "      <td>11.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0      1      2       3     4  old y/target  y predicted by rfe\n",
              "0    0.00632  0.538  6.575  4.0900  4.98          24.0                24.0\n",
              "1    0.02731  0.469  6.421  4.9671  9.14          21.6                21.6\n",
              "2    0.02729  0.469  7.185  4.9671  4.03          34.7                34.7\n",
              "3    0.03237  0.458  6.998  6.0622  2.94          33.4                33.4\n",
              "4    0.06905  0.458  7.147  6.0622  5.33          36.2                36.2\n",
              "..       ...    ...    ...     ...   ...           ...                 ...\n",
              "501  0.06263  0.573  6.593  2.4786  9.67          22.4                22.4\n",
              "502  0.04527  0.573  6.120  2.2875  9.08          20.6                20.6\n",
              "503  0.06076  0.573  6.976  2.1675  5.64          23.9                23.9\n",
              "504  0.10959  0.573  6.794  2.3889  6.48          22.0                22.0\n",
              "505  0.04741  0.573  6.030  2.5050  7.88          11.9                11.9\n",
              "\n",
              "[506 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zUMVRDinefI",
        "outputId": "b7024189-88a1-4204-9a39-39a2149aa827"
      },
      "source": [
        "#Label Encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_le = le.fit_transform(boston_rfe['y predicted by rfe'])\n",
        "print(y_le.shape, type(y_le), y_le)\n",
        "boston_le = pd.DataFrame(boston_rfe)\n",
        "boston_le['label encoded y'] = y_le\n",
        "print(boston_le)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506,) <class 'numpy.ndarray'> [137 113 196 193 203 165 126 156  64  87  52  87 114 102  80  97 128  73\n",
            " 100  80  40  94  54  48  57  42  65  50  82 108  32  48  36  35  39  87\n",
            "  98 108 144 176 197 153 149 144 110  91  98  65  47  92  95 103 146 131\n",
            "  87 200 144 181 130  94  85  59 119 146 189 132  92 117  72 107 139 114\n",
            " 125 131 138 111  98 106 110 101 159 136 145 126 136 153 122 119 133 165\n",
            " 123 117 126 146 104 162 111 211 219 191 157 152  84  91  99  93  93 102\n",
            "  96  92 114 125  86  85  83  81 110  90 102  91 117 101 103  71  86 111\n",
            "  58  61  78  46  90  94 127  82  57  79  72  69  37  76  43  47  38  57\n",
            "  25  41  57  49  76  56 112  94  55  92  68  57  35 213 140 130 155 228\n",
            " 228 228 124 146 228 135 135 120  72  89 128 133 123 168 129 143 171 207\n",
            " 212 203 210 186 151 169 228 183 170 197 206 174 204 178 167 228 192 173\n",
            " 195 197 188 138 215 226 228 123 141 122 141  98 114  91 121 160 134 146\n",
            " 130 165 112 127 154 114 157 172 221 228 209 181 224 180 140 182 214 225\n",
            " 166 137 147 180 134 130 117  99 119 134  74  83 140 103 142 150 141 145\n",
            " 169 216 116 107 220 228 201 172 194 217 227 177 205 125 175 228 218 105\n",
            " 109 148 141 199 185 183 191 190 167 198 222 200 223 228 184 117  99 129\n",
            " 120 145 163 208 158 136 114 164 156 101 122 166 145 117 151 190 202 162\n",
            " 193 161 125 101  60 118  92 113 135  61  76  96 128 108 135 128 102  83\n",
            " 146 143 127 119  91 123  96  69  92 119 105 109  93  83 104  88  85 187\n",
            "  64 136 179  73  70 128 142 153 126 138  84 172  80 104  76 114 124 123\n",
            " 146  97 106  67 116 157 116 128 228 228 228 228 228  41  41  52  42  37\n",
            "  35  16  17  20  22  29  12   4  18   5  16  23  53 129  15  41  32  35\n",
            "  30  10   0   2   1   4  28   8  10   0  26 158  70 157  52  70  77  62\n",
            "   3   4   6  17  12   9  66  45 106  38  24   8  16  20  21  13  48  44\n",
            "  60  46  24  38  14  11   9  33  18  69  82  56  19  25  51  31  44  34\n",
            "  38  54  60  76  51  44  32  39  51  98  63  75  93 100 111  97  88  89\n",
            "  89  99  97  94 129 170  41  37  66  27  49 111 127 134 146 115 104 110\n",
            "  89 104  54   3   7  40  99 115 142 128  95  81 110  73  67 121 104 136\n",
            " 117  26]\n",
            "           0      1      2  ...  old y/target  y predicted by rfe  label encoded y\n",
            "0    0.00632  0.538  6.575  ...          24.0                24.0              137\n",
            "1    0.02731  0.469  6.421  ...          21.6                21.6              113\n",
            "2    0.02729  0.469  7.185  ...          34.7                34.7              196\n",
            "3    0.03237  0.458  6.998  ...          33.4                33.4              193\n",
            "4    0.06905  0.458  7.147  ...          36.2                36.2              203\n",
            "..       ...    ...    ...  ...           ...                 ...              ...\n",
            "501  0.06263  0.573  6.593  ...          22.4                22.4              121\n",
            "502  0.04527  0.573  6.120  ...          20.6                20.6              104\n",
            "503  0.06076  0.573  6.976  ...          23.9                23.9              136\n",
            "504  0.10959  0.573  6.794  ...          22.0                22.0              117\n",
            "505  0.04741  0.573  6.030  ...          11.9                11.9               26\n",
            "\n",
            "[506 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObMaq1fTpPB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e103cc7a-34a4-46d8-c1c0-4abfdda937de"
      },
      "source": [
        "# One Hot Encoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder()\n",
        "print(ohe)\n",
        "print(pd.DataFrame(boston_rfe.iloc[:,6]))\n",
        "s1 = pd.DataFrame(ohe.fit_transform(pd.DataFrame(boston_rfe.iloc[:,6])))\n",
        "print(type(s1),s1)\n",
        "boston_ohe = pd.concat([boston_rfe,s1], axis=1)\n",
        "print(boston_ohe) # C'est Incomplete\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
            "              handle_unknown='error', sparse=True)\n",
            "     y predicted by rfe\n",
            "0                  24.0\n",
            "1                  21.6\n",
            "2                  34.7\n",
            "3                  33.4\n",
            "4                  36.2\n",
            "..                  ...\n",
            "501                22.4\n",
            "502                20.6\n",
            "503                23.9\n",
            "504                22.0\n",
            "505                11.9\n",
            "\n",
            "[506 rows x 1 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>                    0\n",
            "0      (0, 137)\\t1.0\n",
            "1      (0, 113)\\t1.0\n",
            "2      (0, 196)\\t1.0\n",
            "3      (0, 193)\\t1.0\n",
            "4      (0, 203)\\t1.0\n",
            "..               ...\n",
            "501    (0, 121)\\t1.0\n",
            "502    (0, 104)\\t1.0\n",
            "503    (0, 136)\\t1.0\n",
            "504    (0, 117)\\t1.0\n",
            "505     (0, 26)\\t1.0\n",
            "\n",
            "[506 rows x 1 columns]\n",
            "           0      1  ...  label encoded y                0\n",
            "0    0.00632  0.538  ...              137    (0, 137)\\t1.0\n",
            "1    0.02731  0.469  ...              113    (0, 113)\\t1.0\n",
            "2    0.02729  0.469  ...              196    (0, 196)\\t1.0\n",
            "3    0.03237  0.458  ...              193    (0, 193)\\t1.0\n",
            "4    0.06905  0.458  ...              203    (0, 203)\\t1.0\n",
            "..       ...    ...  ...              ...              ...\n",
            "501  0.06263  0.573  ...              121    (0, 121)\\t1.0\n",
            "502  0.04527  0.573  ...              104    (0, 104)\\t1.0\n",
            "503  0.06076  0.573  ...              136    (0, 136)\\t1.0\n",
            "504  0.10959  0.573  ...              117    (0, 117)\\t1.0\n",
            "505  0.04741  0.573  ...               26     (0, 26)\\t1.0\n",
            "\n",
            "[506 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs2PLMwL35na",
        "outputId": "20fe9458-9844-49bf-ab80-f229e6a7a225"
      },
      "source": [
        "# One Hot Encoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(sparse=False) #key is to set sparse = False as the default sparse is True.\n",
        "print(ohe)\n",
        "print(boston.iloc[:,:-1])\n",
        "boston_ohe = ohe.fit_transform(boston.iloc[:,:-1])\n",
        "print(type(boston_ohe),boston_ohe)\n",
        "boston_ohe_df = pd.DataFrame(boston_ohe)\n",
        "print(boston_ohe_df,'\\n', boston_ohe_df.describe())"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
            "              handle_unknown='error', sparse=False)\n",
            "        CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n",
            "0    0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.90   4.98\n",
            "1    0.02731   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  396.90   9.14\n",
            "2    0.02729   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  392.83   4.03\n",
            "3    0.03237   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  394.63   2.94\n",
            "4    0.06905   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  396.90   5.33\n",
            "..       ...   ...    ...   ...    ...  ...  ...    ...      ...     ...    ...\n",
            "501  0.06263   0.0  11.93   0.0  0.573  ...  1.0  273.0     21.0  391.99   9.67\n",
            "502  0.04527   0.0  11.93   0.0  0.573  ...  1.0  273.0     21.0  396.90   9.08\n",
            "503  0.06076   0.0  11.93   0.0  0.573  ...  1.0  273.0     21.0  396.90   5.64\n",
            "504  0.10959   0.0  11.93   0.0  0.573  ...  1.0  273.0     21.0  393.45   6.48\n",
            "505  0.04741   0.0  11.93   0.0  0.573  ...  1.0  273.0     21.0  396.90   7.88\n",
            "\n",
            "[506 rows x 13 columns]\n",
            "<class 'numpy.ndarray'> [[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "     0     1     2     3     4     5     ...  2830  2831  2832  2833  2834  2835\n",
            "0     1.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
            "1     0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
            "2     0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
            "3     0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
            "4     0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
            "..    ...   ...   ...   ...   ...   ...  ...   ...   ...   ...   ...   ...   ...\n",
            "501   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
            "502   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
            "503   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
            "504   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
            "505   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0\n",
            "\n",
            "[506 rows x 2836 columns] \n",
            "              0           1           2     ...        2833        2834        2835\n",
            "count  506.000000  506.000000  506.000000  ...  506.000000  506.000000  506.000000\n",
            "mean     0.001976    0.001976    0.001976  ...    0.001976    0.001976    0.001976\n",
            "std      0.044455    0.044455    0.044455  ...    0.044455    0.044455    0.044455\n",
            "min      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
            "25%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
            "50%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
            "75%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
            "max      1.000000    1.000000    1.000000  ...    1.000000    1.000000    1.000000\n",
            "\n",
            "[8 rows x 2836 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX0mkmPfq8aS",
        "outputId": "7efa8187-5412-48cb-a9c6-72970f7e207e"
      },
      "source": [
        "#get dummies\n",
        "boston_dummies = pd.get_dummies(boston)\n",
        "print(boston_dummies, '\\n', boston_dummies.describe())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  target\n",
            "0    0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98    24.0\n",
            "1    0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14    21.6\n",
            "2    0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03    34.7\n",
            "3    0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94    33.4\n",
            "4    0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33    36.2\n",
            "..       ...   ...    ...   ...    ...  ...    ...      ...     ...    ...     ...\n",
            "501  0.06263   0.0  11.93   0.0  0.573  ...  273.0     21.0  391.99   9.67    22.4\n",
            "502  0.04527   0.0  11.93   0.0  0.573  ...  273.0     21.0  396.90   9.08    20.6\n",
            "503  0.06076   0.0  11.93   0.0  0.573  ...  273.0     21.0  396.90   5.64    23.9\n",
            "504  0.10959   0.0  11.93   0.0  0.573  ...  273.0     21.0  393.45   6.48    22.0\n",
            "505  0.04741   0.0  11.93   0.0  0.573  ...  273.0     21.0  396.90   7.88    11.9\n",
            "\n",
            "[506 rows x 14 columns] \n",
            "              CRIM          ZN       INDUS  ...           B       LSTAT      target\n",
            "count  506.000000  506.000000  506.000000  ...  506.000000  506.000000  506.000000\n",
            "mean     3.613524   11.363636   11.136779  ...  356.674032   12.653063   22.532806\n",
            "std      8.601545   23.322453    6.860353  ...   91.294864    7.141062    9.197104\n",
            "min      0.006320    0.000000    0.460000  ...    0.320000    1.730000    5.000000\n",
            "25%      0.082045    0.000000    5.190000  ...  375.377500    6.950000   17.025000\n",
            "50%      0.256510    0.000000    9.690000  ...  391.440000   11.360000   21.200000\n",
            "75%      3.677083   12.500000   18.100000  ...  396.225000   16.955000   25.000000\n",
            "max     88.976200  100.000000   27.740000  ...  396.900000   37.970000   50.000000\n",
            "\n",
            "[8 rows x 14 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hROUU_q5se_N",
        "outputId": "ca9f62c7-2a39-4383-bb80-b29ee207c3bc"
      },
      "source": [
        "pd.get_dummies(boston_le)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>old y/target</th>\n",
              "      <th>y predicted by rfe</th>\n",
              "      <th>label encoded y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>21.6</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>34.7</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "      <td>33.4</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "      <td>36.2</td>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0.06263</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.593</td>\n",
              "      <td>2.4786</td>\n",
              "      <td>9.67</td>\n",
              "      <td>22.4</td>\n",
              "      <td>22.4</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0.04527</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.120</td>\n",
              "      <td>2.2875</td>\n",
              "      <td>9.08</td>\n",
              "      <td>20.6</td>\n",
              "      <td>20.6</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0.06076</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.976</td>\n",
              "      <td>2.1675</td>\n",
              "      <td>5.64</td>\n",
              "      <td>23.9</td>\n",
              "      <td>23.9</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>0.10959</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.794</td>\n",
              "      <td>2.3889</td>\n",
              "      <td>6.48</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.030</td>\n",
              "      <td>2.5050</td>\n",
              "      <td>7.88</td>\n",
              "      <td>11.9</td>\n",
              "      <td>11.9</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506 rows  8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0      1      2  ...  old y/target  y predicted by rfe  label encoded y\n",
              "0    0.00632  0.538  6.575  ...          24.0                24.0              137\n",
              "1    0.02731  0.469  6.421  ...          21.6                21.6              113\n",
              "2    0.02729  0.469  7.185  ...          34.7                34.7              196\n",
              "3    0.03237  0.458  6.998  ...          33.4                33.4              193\n",
              "4    0.06905  0.458  7.147  ...          36.2                36.2              203\n",
              "..       ...    ...    ...  ...           ...                 ...              ...\n",
              "501  0.06263  0.573  6.593  ...          22.4                22.4              121\n",
              "502  0.04527  0.573  6.120  ...          20.6                20.6              104\n",
              "503  0.06076  0.573  6.976  ...          23.9                23.9              136\n",
              "504  0.10959  0.573  6.794  ...          22.0                22.0              117\n",
              "505  0.04741  0.573  6.030  ...          11.9                11.9               26\n",
              "\n",
              "[506 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0AY_HuchC-XI",
        "outputId": "560a9462-2393-4b49-a392-13450578044d"
      },
      "source": [
        "#LabelBinarizer is applied only on the target variable while one hot encoding is applied on the dataframe or features.\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "print(boston['target'])\n",
        "val = boston['target'].values\n",
        "print(type(val), val)\n",
        "#boston_lb_y = lb.fit(val) # Not Working yet"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0      24.0\n",
            "1      21.6\n",
            "2      34.7\n",
            "3      33.4\n",
            "4      36.2\n",
            "       ... \n",
            "501    22.4\n",
            "502    20.6\n",
            "503    23.9\n",
            "504    22.0\n",
            "505    11.9\n",
            "Name: target, Length: 506, dtype: float64\n",
            "<class 'numpy.ndarray'> [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
            " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
            " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
            " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
            " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
            " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
            " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
            " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
            " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
            " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
            " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
            " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
            " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
            " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
            " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
            " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
            " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
            " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
            " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
            " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
            " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
            " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
            " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
            " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
            " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
            " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
            " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
            " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
            "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
            " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
            " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
            " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
            " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
            " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
            " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
            "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
            " 22.  11.9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-047c9f08ba1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboston\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mboston_lb_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Not Working yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7A_2SBuDtg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb4d3487-fa0e-4981-96ed-b1829678fc0b"
      },
      "source": [
        "#numerical to categorical binning\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "kbd = KBinsDiscretizer()\n",
        "#df1_binned = kbd.fit_transform(df1)\n",
        "boston_df = pd.DataFrame(load_boston()['data'])\n",
        "print(boston_df)\n",
        "boston_df = boston_df.iloc[:,9:12]\n",
        "print(boston_df)\n",
        "boston_kbd = kbd.fit_transform(boston_df)\n",
        "print(boston_kbd)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0     1      2    3      4   ...   8      9     10      11    12\n",
            "0    0.00632  18.0   2.31  0.0  0.538  ...  1.0  296.0  15.3  396.90  4.98\n",
            "1    0.02731   0.0   7.07  0.0  0.469  ...  2.0  242.0  17.8  396.90  9.14\n",
            "2    0.02729   0.0   7.07  0.0  0.469  ...  2.0  242.0  17.8  392.83  4.03\n",
            "3    0.03237   0.0   2.18  0.0  0.458  ...  3.0  222.0  18.7  394.63  2.94\n",
            "4    0.06905   0.0   2.18  0.0  0.458  ...  3.0  222.0  18.7  396.90  5.33\n",
            "..       ...   ...    ...  ...    ...  ...  ...    ...   ...     ...   ...\n",
            "501  0.06263   0.0  11.93  0.0  0.573  ...  1.0  273.0  21.0  391.99  9.67\n",
            "502  0.04527   0.0  11.93  0.0  0.573  ...  1.0  273.0  21.0  396.90  9.08\n",
            "503  0.06076   0.0  11.93  0.0  0.573  ...  1.0  273.0  21.0  396.90  5.64\n",
            "504  0.10959   0.0  11.93  0.0  0.573  ...  1.0  273.0  21.0  393.45  6.48\n",
            "505  0.04741   0.0  11.93  0.0  0.573  ...  1.0  273.0  21.0  396.90  7.88\n",
            "\n",
            "[506 rows x 13 columns]\n",
            "        9     10      11\n",
            "0    296.0  15.3  396.90\n",
            "1    242.0  17.8  396.90\n",
            "2    242.0  17.8  392.83\n",
            "3    222.0  18.7  394.63\n",
            "4    222.0  18.7  396.90\n",
            "..     ...   ...     ...\n",
            "501  273.0  21.0  391.99\n",
            "502  273.0  21.0  396.90\n",
            "503  273.0  21.0  396.90\n",
            "504  273.0  21.0  393.45\n",
            "505  273.0  21.0  396.90\n",
            "\n",
            "[506 rows x 3 columns]\n",
            "  (0, 1)\t1.0\n",
            "  (0, 5)\t1.0\n",
            "  (0, 13)\t1.0\n",
            "  (1, 0)\t1.0\n",
            "  (1, 6)\t1.0\n",
            "  (1, 13)\t1.0\n",
            "  (2, 0)\t1.0\n",
            "  (2, 6)\t1.0\n",
            "  (2, 12)\t1.0\n",
            "  (3, 0)\t1.0\n",
            "  (3, 7)\t1.0\n",
            "  (3, 13)\t1.0\n",
            "  (4, 0)\t1.0\n",
            "  (4, 7)\t1.0\n",
            "  (4, 13)\t1.0\n",
            "  (5, 0)\t1.0\n",
            "  (5, 7)\t1.0\n",
            "  (5, 13)\t1.0\n",
            "  (6, 2)\t1.0\n",
            "  (6, 5)\t1.0\n",
            "  (6, 13)\t1.0\n",
            "  (7, 2)\t1.0\n",
            "  (7, 5)\t1.0\n",
            "  (7, 13)\t1.0\n",
            "  (8, 2)\t1.0\n",
            "  :\t:\n",
            "  (497, 13)\t1.0\n",
            "  (498, 2)\t1.0\n",
            "  (498, 7)\t1.0\n",
            "  (498, 13)\t1.0\n",
            "  (499, 2)\t1.0\n",
            "  (499, 7)\t1.0\n",
            "  (499, 13)\t1.0\n",
            "  (500, 2)\t1.0\n",
            "  (500, 7)\t1.0\n",
            "  (500, 13)\t1.0\n",
            "  (501, 1)\t1.0\n",
            "  (501, 9)\t1.0\n",
            "  (501, 12)\t1.0\n",
            "  (502, 1)\t1.0\n",
            "  (502, 9)\t1.0\n",
            "  (502, 13)\t1.0\n",
            "  (503, 1)\t1.0\n",
            "  (503, 9)\t1.0\n",
            "  (503, 13)\t1.0\n",
            "  (504, 1)\t1.0\n",
            "  (504, 9)\t1.0\n",
            "  (504, 12)\t1.0\n",
            "  (505, 1)\t1.0\n",
            "  (505, 9)\t1.0\n",
            "  (505, 13)\t1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_discretization.py:197: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
            "  'decreasing the number of bins.' % jj)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCso63zy1hNZ",
        "outputId": "0868b2eb-2f9a-496d-abfc-d35b40112553"
      },
      "source": [
        "print(df)\n",
        "df4kbd = df.iloc[:5,[18,24]]\n",
        "print(df4kbd)\n",
        "kbd_binned = kbd.fit_transform(df4kbd)\n",
        "print(kbd_binned)\n",
        "import scipy\n",
        "print(scipy.sparse.csr_matrix.toarray(kbd_binned))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      0    1          2      3      4     5   ...   22   23       24   25   26   27\n",
            "0    2.0  1.0   530101.0  38.50   66.0  28.0  ...  2.0  2.0  11300.0  0.0  0.0  2.0\n",
            "1    1.0  1.0   534817.0  39.20   88.0  20.0  ...  3.0  2.0   2208.0  0.0  0.0  2.0\n",
            "2    2.0  1.0   530334.0  38.30   40.0  24.0  ...  1.0  2.0      0.0  0.0  0.0  1.0\n",
            "3    1.0  9.0  5290409.0  39.10  164.0  84.0  ...  2.0  1.0   2208.0  0.0  0.0  1.0\n",
            "4    2.0  1.0   530255.0  37.30  104.0  35.0  ...  2.0  2.0   4300.0  0.0  0.0  2.0\n",
            "..   ...  ...        ...    ...    ...   ...  ...  ...  ...      ...  ...  ...  ...\n",
            "295  1.0  1.0   533886.0  38.18  120.0  70.0  ...  3.0  2.0   3205.0  0.0  0.0  2.0\n",
            "296  2.0  1.0   527702.0  37.20   72.0  24.0  ...  3.0  1.0   2208.0  0.0  0.0  1.0\n",
            "297  1.0  1.0   529386.0  37.50   72.0  30.0  ...  2.0  1.0   3205.0  0.0  0.0  2.0\n",
            "298  1.0  1.0   530612.0  36.50  100.0  24.0  ...  1.0  1.0   2208.0  0.0  0.0  1.0\n",
            "299  1.0  1.0   534618.0  37.20   40.0  20.0  ...  3.0  2.0   6112.0  0.0  0.0  2.0\n",
            "\n",
            "[300 rows x 28 columns]\n",
            "     18       24\n",
            "0  45.0  11300.0\n",
            "1  50.0   2208.0\n",
            "2  33.0      0.0\n",
            "3  48.0   2208.0\n",
            "4  74.0   4300.0\n",
            "  (0, 1)\t1.0\n",
            "  (0, 9)\t1.0\n",
            "  (1, 3)\t1.0\n",
            "  (1, 7)\t1.0\n",
            "  (2, 0)\t1.0\n",
            "  (2, 5)\t1.0\n",
            "  (3, 2)\t1.0\n",
            "  (3, 7)\t1.0\n",
            "  (4, 4)\t1.0\n",
            "  (4, 8)\t1.0\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpbMt7EL198J",
        "outputId": "cfa6d32c-0898-4de1-bec6-7f0c691c7f47"
      },
      "source": [
        "kbd1 = KBinsDiscretizer(n_bins=10,encode='ordinal',strategy='uniform') #ordinal and uniform are not API's original choices and we need to define these separately.\n",
        "df_binned1 = kbd1.fit_transform(df4kbd)\n",
        "print(df_binned1)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2. 9.]\n",
            " [4. 1.]\n",
            " [0. 0.]\n",
            " [3. 1.]\n",
            " [9. 3.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzH7dQsA5bEp",
        "outputId": "1c57085a-0516-492c-a005-4d46cd475a70"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax = MinMaxScaler()\n",
        "boston_df_mm = minmax.fit_transform(boston_df)\n",
        "print(boston_df_mm, boston_df_mm.shape)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.20801527 0.28723404 1.        ]\n",
            " [0.10496183 0.55319149 1.        ]\n",
            " [0.10496183 0.55319149 0.98973725]\n",
            " ...\n",
            " [0.16412214 0.89361702 1.        ]\n",
            " [0.16412214 0.89361702 0.99130062]\n",
            " [0.16412214 0.89361702 1.        ]] (506, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz3yTVPl7jO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a54d48-071c-4ef8-ff85-fe2492f64ae8"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n",
        "for i in cancer:\n",
        "  print(i)\n",
        "  print(cancer[i])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\n",
            "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
            " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
            " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
            " ...\n",
            " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
            " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
            " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
            "target\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
            "target_names\n",
            "['malignant' 'benign']\n",
            "DESCR\n",
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry \n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
            "        13 is Radius SE, field 23 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n",
            "feature_names\n",
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "filename\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/breast_cancer.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cShqogWyj4Hl",
        "outputId": "afa8644e-5a35-4113-990e-e2299f8f8919"
      },
      "source": [
        "print(cancer['data'].shape, cancer['data'])\n",
        "print(cancer['target'].shape, cancer['target'])\n",
        "print(cancer.feature_names, len(cancer.feature_names))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30) [[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
            " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
            " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
            " ...\n",
            " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
            " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
            " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
            "(569,) [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension'] 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "FpMuXbr0ktn2",
        "outputId": "d7f2edd2-d64f-41ef-c52b-cf7dc71dc542"
      },
      "source": [
        "cancer_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "cancer_df['target'] = cancer.target\n",
        "cancer_df"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows  31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0          17.99         10.38  ...                  0.11890       0\n",
              "1          20.57         17.77  ...                  0.08902       0\n",
              "2          19.69         21.25  ...                  0.08758       0\n",
              "3          11.42         20.38  ...                  0.17300       0\n",
              "4          20.29         14.34  ...                  0.07678       0\n",
              "..           ...           ...  ...                      ...     ...\n",
              "564        21.56         22.39  ...                  0.07115       0\n",
              "565        20.13         28.25  ...                  0.06637       0\n",
              "566        16.60         28.08  ...                  0.07820       0\n",
              "567        20.60         29.33  ...                  0.12400       0\n",
              "568         7.76         24.54  ...                  0.07039       1\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrZ8URfBlCCQ",
        "outputId": "424cba21-0bf1-49de-cb71-739b1bdb6593"
      },
      "source": [
        "# Understanding One Hot Encoding in detail\n",
        "print(pd.get_dummies(cancer_df['mean radius']))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     6.981   7.691   7.729   7.760   ...  25.730  27.220  27.420  28.110\n",
            "0         0       0       0       0  ...       0       0       0       0\n",
            "1         0       0       0       0  ...       0       0       0       0\n",
            "2         0       0       0       0  ...       0       0       0       0\n",
            "3         0       0       0       0  ...       0       0       0       0\n",
            "4         0       0       0       0  ...       0       0       0       0\n",
            "..      ...     ...     ...     ...  ...     ...     ...     ...     ...\n",
            "564       0       0       0       0  ...       0       0       0       0\n",
            "565       0       0       0       0  ...       0       0       0       0\n",
            "566       0       0       0       0  ...       0       0       0       0\n",
            "567       0       0       0       0  ...       0       0       0       0\n",
            "568       0       0       0       1  ...       0       0       0       0\n",
            "\n",
            "[569 rows x 456 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58UahkQFlPUT",
        "outputId": "3b200203-b524-42a5-840b-8fe7b2ad618a"
      },
      "source": [
        "print(cancer.values())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_values([array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
            "        1.189e-01],\n",
            "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
            "        8.902e-02],\n",
            "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
            "        8.758e-02],\n",
            "       ...,\n",
            "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
            "        7.820e-02],\n",
            "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
            "        1.240e-01],\n",
            "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
            "        7.039e-02]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
            "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
            "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
            "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
            "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), array(['malignant', 'benign'], dtype='<U9'), '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
            "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
            "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
            "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
            "       'smoothness error', 'compactness error', 'concavity error',\n",
            "       'concave points error', 'symmetry error',\n",
            "       'fractal dimension error', 'worst radius', 'worst texture',\n",
            "       'worst perimeter', 'worst area', 'worst smoothness',\n",
            "       'worst compactness', 'worst concavity', 'worst concave points',\n",
            "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), '/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/breast_cancer.csv'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIfvz6zGnKTv"
      },
      "source": [
        "#print(cancer_df.values()) # Error 'numpy.ndarray' object is not callable"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Ewadv9nbIk",
        "outputId": "5de35a15-b3d8-4dff-dbf3-eebe0a1081c4"
      },
      "source": [
        "ohe1 = OneHotEncoder(sparse=False)\n",
        "X_oe = ohe1.fit_transform(cancer.data)\n",
        "print(X_oe.shape, type(X_oe), X_oe)\n",
        "X_oe_df = pd.DataFrame(X_oe)\n",
        "print(X_oe_df,'\\n', X_oe_df.describe())"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 15340) <class 'numpy.ndarray'> [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "     0      1      2      3      4      ...  15335  15336  15337  15338  15339\n",
            "0      0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
            "1      0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
            "2      0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
            "3      0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    1.0    0.0\n",
            "4      0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
            "..     ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
            "564    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
            "565    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
            "566    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
            "567    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
            "568    0.0    0.0    0.0    1.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
            "\n",
            "[569 rows x 15340 columns] \n",
            "             0           1           2      ...       15337       15338       15339\n",
            "count  569.000000  569.000000  569.000000  ...  569.000000  569.000000  569.000000\n",
            "mean     0.001757    0.001757    0.001757  ...    0.001757    0.001757    0.001757\n",
            "std      0.041922    0.041922    0.041922  ...    0.041922    0.041922    0.041922\n",
            "min      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
            "25%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
            "50%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
            "75%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
            "max      1.000000    1.000000    1.000000  ...    1.000000    1.000000    1.000000\n",
            "\n",
            "[8 rows x 15340 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSemXjiun7rE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05248c20-d54b-4ae7-ca7c-b9290f7ab991"
      },
      "source": [
        "ohe1 = OneHotEncoder(sparse=True)\n",
        "X_oe = ohe1.fit_transform(cancer.data)\n",
        "print(X_oe.shape, type(X_oe), X_oe)\n",
        "X_oe_df = pd.DataFrame(X_oe)\n",
        "print(X_oe_df,'\\n', X_oe_df.describe())"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 15340) <class 'scipy.sparse.csr.csr_matrix'>   (0, 370)\t1.0\n",
            "  (0, 457)\t1.0\n",
            "  (0, 1390)\t1.0\n",
            "  (0, 1909)\t1.0\n",
            "  (0, 2440)\t1.0\n",
            "  (0, 3001)\t1.0\n",
            "  (0, 3528)\t1.0\n",
            "  (0, 4070)\t1.0\n",
            "  (0, 4502)\t1.0\n",
            "  (0, 5001)\t1.0\n",
            "  (0, 5542)\t1.0\n",
            "  (0, 5726)\t1.0\n",
            "  (0, 6596)\t1.0\n",
            "  (0, 7124)\t1.0\n",
            "  (0, 7414)\t1.0\n",
            "  (0, 8173)\t1.0\n",
            "  (0, 8685)\t1.0\n",
            "  (0, 9158)\t1.0\n",
            "  (0, 9704)\t1.0\n",
            "  (0, 10252)\t1.0\n",
            "  (0, 10733)\t1.0\n",
            "  (0, 10806)\t1.0\n",
            "  (0, 11773)\t1.0\n",
            "  (0, 12306)\t1.0\n",
            "  (0, 12692)\t1.0\n",
            "  :\t:\n",
            "  (568, 2507)\t1.0\n",
            "  (568, 3007)\t1.0\n",
            "  (568, 3544)\t1.0\n",
            "  (568, 4177)\t1.0\n",
            "  (568, 4666)\t1.0\n",
            "  (568, 5347)\t1.0\n",
            "  (568, 5923)\t1.0\n",
            "  (568, 6377)\t1.0\n",
            "  (568, 6761)\t1.0\n",
            "  (568, 7482)\t1.0\n",
            "  (568, 7688)\t1.0\n",
            "  (568, 8225)\t1.0\n",
            "  (568, 8758)\t1.0\n",
            "  (568, 9671)\t1.0\n",
            "  (568, 9985)\t1.0\n",
            "  (568, 10316)\t1.0\n",
            "  (568, 11152)\t1.0\n",
            "  (568, 11283)\t1.0\n",
            "  (568, 11797)\t1.0\n",
            "  (568, 12344)\t1.0\n",
            "  (568, 12762)\t1.0\n",
            "  (568, 13274)\t1.0\n",
            "  (568, 13813)\t1.0\n",
            "  (568, 14577)\t1.0\n",
            "  (568, 14926)\t1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/algorithms.py:797: SparseEfficiencyWarning: Comparing sparse matrices using == is inefficient, try using != instead.\n",
            "  keys, counts = _value_counts_arraylike(values, dropna)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                                     0\n",
            "0      (0, 370)\\t1.0\\n  (0, 457)\\t1.0\\n  (0, 1390)\\...\n",
            "1      (0, 426)\\t1.0\\n  (0, 642)\\t1.0\\n  (0, 1421)\\...\n",
            "2      (0, 406)\\t1.0\\n  (0, 780)\\t1.0\\n  (0, 1413)\\...\n",
            "3      (0, 98)\\t1.0\\n  (0, 753)\\t1.0\\n  (0, 1099)\\t...\n",
            "4      (0, 418)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 1428)\\...\n",
            "..                                                 ...\n",
            "564    (0, 438)\\t1.0\\n  (0, 826)\\t1.0\\n  (0, 1438)\\...\n",
            "565    (0, 413)\\t1.0\\n  (0, 919)\\t1.0\\n  (0, 1418)\\...\n",
            "566    (0, 340)\\t1.0\\n  (0, 914)\\t1.0\\n  (0, 1345)\\...\n",
            "567    (0, 429)\\t1.0\\n  (0, 923)\\t1.0\\n  (0, 1435)\\...\n",
            "568    (0, 3)\\t1.0\\n  (0, 870)\\t1.0\\n  (0, 936)\\t1....\n",
            "\n",
            "[569 rows x 1 columns] \n",
            "                                                         0\n",
            "count                                                 569\n",
            "unique                                                569\n",
            "top       (0, 416)\\t1.0\\n  (0, 900)\\t1.0\\n  (0, 1423)\\...\n",
            "freq                                                    1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFGOE9Se00bK"
      },
      "source": [
        ""
      ],
      "execution_count": 80,
      "outputs": []
    }
  ]
}